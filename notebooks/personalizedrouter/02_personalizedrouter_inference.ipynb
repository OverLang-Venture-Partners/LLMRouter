{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PersonalizedRouter - Inference\n",
    "\n",
    "This notebook demonstrates how to use a trained **PersonalizedRouter** for inference.\n",
    "\n",
    "## Overview\n",
    "\n",
    "PersonalizedRouter supports both:\n",
    "- **Single query routing** with `route_single()`\n",
    "- **Batch routing** with `route_batch()`\n",
    "\n",
    "The router considers user features for personalized routing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "os.chdir(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llmrouter.models.personalizedrouter import PersonalizedRouter\n",
    "from llmrouter.utils import setup_environment\n",
    "import yaml\n",
    "\n",
    "setup_environment()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Load Trained Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"configs/model_config_train/personalizedrouter.yaml\"\n",
    "\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "router = PersonalizedRouter(yaml_path=CONFIG_PATH)\n",
    "print(f\"Router loaded with {len(router.llm_data)} LLM candidates\")\n",
    "print(f\"Number of users: {router.num_users}\")\n",
    "print(f\"Number of tasks: {router.num_task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Single Query Routing\n",
    "\n",
    "Route a single query with optional user_id for personalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries\n",
    "EXAMPLE_QUERIES = [\n",
    "    {\"query\": \"What is the capital of France?\", \"user_id\": 0},\n",
    "    {\"query\": \"Solve the equation: 2x + 5 = 15\", \"user_id\": 1},\n",
    "    {\"query\": \"Write a Python function to check if a number is prime.\", \"user_id\": 2},\n",
    "    {\"query\": \"Explain quantum computing in simple terms.\", \"user_id\": 0},\n",
    "]\n",
    "\n",
    "print(\"Routing Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(EXAMPLE_QUERIES, 1):\n",
    "    result = router.route_single(query)\n",
    "    print(f\"{i}. Query: {query['query'][:50]}...\")\n",
    "    print(f\"   User ID: {query.get('user_id', 'N/A')}\")\n",
    "    print(f\"   Routed to: {result['model_name']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Batch Routing\n",
    "\n",
    "Route multiple queries efficiently using batch inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare batch queries\n",
    "batch_queries = [\n",
    "    {\"query\": \"What is the capital of France?\", \"user_id\": 0},\n",
    "    {\"query\": \"Who wrote Romeo and Juliet?\", \"user_id\": 1},\n",
    "    {\"query\": \"How does photosynthesis work?\", \"user_id\": 2},\n",
    "    {\"query\": \"What is the speed of light?\", \"user_id\": 0},\n",
    "    {\"query\": \"Explain the theory of relativity.\", \"user_id\": 1},\n",
    "]\n",
    "\n",
    "print(\"Batch Routing Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Route batch\n",
    "batch_results = router.route_batch(batch=batch_queries)\n",
    "\n",
    "for i, result in enumerate(batch_results, 1):\n",
    "    print(f\"{i}. Query: {result.get('query', '')[:45]}...\")\n",
    "    print(f\"   User ID: {result.get('user_id', 'N/A')}\")\n",
    "    print(f\"   Routed to: {result['model_name']}\")\n",
    "    if 'response' in result and result['response']:\n",
    "        print(f\"   Response: {result['response'][:80]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. File-Based Inference\n",
    "\n",
    "Load queries from a file and save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load queries from a JSONL file\n",
    "def load_queries_from_file(file_path):\n",
    "    \"\"\"Load queries from a JSONL file.\"\"\"\n",
    "    queries = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                queries.append(json.loads(line))\n",
    "    return queries\n",
    "\n",
    "# Save results to a JSONL file\n",
    "def save_results_to_file(results, output_path):\n",
    "    \"\"\"Save routing results to a JSONL file.\"\"\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for result in results:\n",
    "            f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n",
    "    print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "# Example: Load from default query file\n",
    "QUERY_FILE = \"data/example_data/query_data/default_query_test.jsonl\"\n",
    "OUTPUT_FILE = \"outputs/personalizedrouter_results.jsonl\"\n",
    "\n",
    "if os.path.exists(QUERY_FILE):\n",
    "    # Load queries\n",
    "    file_queries = load_queries_from_file(QUERY_FILE)\n",
    "    print(f\"Loaded {len(file_queries)} queries from: {QUERY_FILE}\")\n",
    "    \n",
    "    # Add user_id if missing (cycle through users)\n",
    "    num_users = int(getattr(router, \"num_users\", 1) or 1)\n",
    "    for i, query in enumerate(file_queries):\n",
    "        query.setdefault('user_id', i % num_users)\n",
    "    \n",
    "    # Route queries (limit to first 10 for demo)\n",
    "    file_results = router.route_batch(batch=file_queries[:10])\n",
    "    print(f\"Routed {len(file_results)} queries\")\n",
    "    \n",
    "    # Save results\n",
    "    save_results_to_file(file_results, OUTPUT_FILE)\n",
    "    \n",
    "    # Show sample results\n",
    "    print(f\"\\nSample results:\")\n",
    "    for i, result in enumerate(file_results[:3], 1):\n",
    "        query_text = result.get('query', '')[:40]\n",
    "        user_id = result.get('user_id', 'N/A')\n",
    "        print(f\"  {i}. {query_text}... (user {user_id}) -> {result['model_name']}\")\n",
    "else:\n",
    "    print(f\"Query file not found: {QUERY_FILE}\")\n",
    "    print(\"Create a JSONL file with format: {\\\"query\\\": \\\"Your question\\\", \\\"user_id\\\": 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Personalized Routing Analysis\n",
    "\n",
    "Analyze how routing differs across users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the same query with different users\n",
    "TEST_QUERY = {\"query\": \"What is the capital of France?\"}\n",
    "\n",
    "print(f\"Test Query: {TEST_QUERY['query']}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Routing results for different users:\")\n",
    "print()\n",
    "\n",
    "user_routing_results = {}\n",
    "for user_id in range(min(5, router.num_users)):\n",
    "    test_query = TEST_QUERY.copy()\n",
    "    test_query['user_id'] = user_id\n",
    "    result = router.route_single(test_query)\n",
    "    user_routing_results[user_id] = result['model_name']\n",
    "    print(f\"User {user_id}: {result['model_name']}\")\n",
    "\n",
    "print()\n",
    "if len(set(user_routing_results.values())) > 1:\n",
    "    print(\"Note: Routing differs across users - personalization is working!\")\n",
    "else:\n",
    "    print(\"Note: All users routed to the same model.\")\n",
    "    print(\"This is expected if training data doesn't show strong user preferences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading a trained PersonalizedRouter\n",
    "2. Single query routing with user personalization\n",
    "3. Batch routing for efficient inference\n",
    "4. File-based inference pipeline\n",
    "5. Personalized routing analysis across users\n",
    "\n",
    "PersonalizedRouter is effective for:\n",
    "- User-specific routing preferences\n",
    "- Multi-user environments\n",
    "- Learning different routing strategies for different users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
